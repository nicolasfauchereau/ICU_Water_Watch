{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### os \n",
    "import os \n",
    "import sys\n",
    "\n",
    "### datetimes \n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "### scipy \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import stats as st\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "# dask \n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "### plotting \n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "HOME = pathlib.Path.home()\n",
    "CWD = pathlib.Path.cwd() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = [125, 240, -35, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ICU_Water_Watch import plot, geo, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directory with the daily GPM-IMERG data (one file per day )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = pathlib.Path('/home/nicolasf/operational/ICU/ops/data/GPM_IMERG/daily/extended_SP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfiles = list(dpath.glob(\"GPM_IMERG_daily.v06.????.??.??.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/nicolasf/operational/ICU/ops/data/GPM_IMERG/daily/extended_SP/GPM_IMERG_daily.v06.2001.01.01.nc')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/nicolasf/operational/ICU/ops/data/GPM_IMERG/daily/extended_SP/GPM_IMERG_daily.v06.2021.10.02.nc')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfiles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7580"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfiles = lfiles[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/nicolasf/operational/ICU/ops/data/GPM_IMERG/daily/extended_SP/GPM_IMERG_daily.v06.2021.09.30.nc')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfiles[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open the multiple file dataset and selects the variable of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = xr.open_mfdataset(lfiles, concat_dim='time', parallel=True)[['precipitationCal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculates the running accumulations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-chunks first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dset.chunk({'time':-1, 'lon':10, 'lat':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running accumulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dset.rolling({'time':ndays}, min_periods=ndays, center=False).sum('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 55.2s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar(): \n",
    "    dset = dset.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get rid of the ndays - 1 first values (missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dset.isel(time=slice(ndays-1, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take the month and day of the last value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day = dset.time.to_index()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cftime.DatetimeJulian(2021, 9, 30, 0, 0, 0, 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buffer (in days) around the date (for taking the corresponding accumulations from the climatology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### climatological period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_period =[2001, 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_daily_clim(dset, last_day, clim_period=[2001, 2020], buffer=3): \n",
    "    \"\"\"\n",
    "    takes a multiple files daily dataset, and extract N days (parameter `buffer`)\n",
    "    around each day of year for a climatological period (parameter `clim_period`)\n",
    "    \"\"\"\n",
    "    \n",
    "    from datetime import datetime\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    import pandas as pd\n",
    "    import xarray as xr \n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    ldates = []\n",
    "    \n",
    "    for y in np.arange(clim_period[0], clim_period[-1] + 1): \n",
    "        \n",
    "        d = datetime(y, last_day.month, last_day.day)\n",
    "        d = [d + relativedelta(days=x) for x in range(-buffer, buffer+1)]\n",
    "        ldates += d\n",
    "    \n",
    "    ldates = np.array(ldates)\n",
    "    dates = pd.Index(ldates)\n",
    "    dates = dates.to_series()\n",
    "    \n",
    "    clim = dset.sel(time=slice(*map(str, clim_period)))\n",
    "    \n",
    "    clim['time'] = clim.indexes['time'].to_datetimeindex()\n",
    "    \n",
    "    dates = dates.loc[clim.time.to_index()[0]:clim.time.to_index()[-1],]\n",
    "    \n",
    "    clim = clim.sel(time=dates.values)\n",
    "    \n",
    "    return clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = subset_daily_clim(dset, last_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_SPI(dset, variable='precipitationCal', dimension='time', return_gamma = False):\n",
    "    \"\"\"\n",
    "    calibrate the SPI over a climatological dataset (typically obtained using `subset_daily_clim`\n",
    "    with appropriate buffer ...)\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np \n",
    "    import xarray as xr \n",
    "    from scipy import stats as st\n",
    "    \n",
    "    ds_ma = dset[variable]\n",
    "    \n",
    "    ds_In = np.log(ds_ma)\n",
    "    ds_In = ds_In.where(np.isinf(ds_In) == False) #= np.nan  #Change infinity to NaN\n",
    "\n",
    "    ds_mu = ds_ma.mean(dimension)\n",
    "\n",
    "    #Overall Mean of Moving Averages\n",
    "    ds_mu = ds_ma.mean(dimension)\n",
    "\n",
    "    #Summation of Natural log of moving averages\n",
    "    ds_sum = ds_In.sum(dimension)\n",
    "\n",
    "    #Computing essentials for gamma distribution\n",
    "    n = ds_In.count(dimension)                  #size of data\n",
    "    A = np.log(ds_mu) - (ds_sum/n)             #Computing A\n",
    "    alpha = (1/(4*A))*(1+(1+((4*A)/3))**0.5)   #Computing alpha  (a)\n",
    "    beta = ds_mu/alpha            \n",
    "    \n",
    "    if return_gamma: \n",
    "\n",
    "        gamma_func = lambda data, a, scale: st.gamma.cdf(data, a=a, scale=scale)\n",
    "\n",
    "        gamma = xr.apply_ufunc(gamma_func, ds_ma, alpha, beta)\n",
    "\n",
    "        return gamma, alpha, beta\n",
    "\n",
    "    else: \n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SPI(dataarray, alpha, beta, name='SPI'): \n",
    "    \n",
    "    import numpy as np \n",
    "    import xarray as xr \n",
    "    from scipy import stats as st\n",
    "    \n",
    "    gamma_func = lambda data, a, scale: st.gamma.cdf(data, a=a, scale=scale)\n",
    "    \n",
    "    gamma = xr.apply_ufunc(gamma_func, dataarray, alpha, beta)\n",
    "    \n",
    "    norminv = lambda data: st.norm.ppf(data, loc=0, scale=1)\n",
    "    \n",
    "    norm_spi = xr.apply_ufunc(norminv, gamma)\n",
    "    \n",
    "    return norm_spi.to_dataset(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = calibrate_SPI(clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_spi_realtime = calculate_SPI(dset['precipitationCal'].isel(time=-1), alpha, beta) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reads in the EEZs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ICU_Water_Watch import geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZs, merged_EEZs = geo.get_EEZs(dpath_shapes='/home/nicolasf/operational/ICU/development/hotspots/data/shapefiles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adds the EEZ mask to the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_spi_realtime = geo.make_mask_from_gpd(norm_spi_realtime, merged_EEZs, subset=True, mask_name='EEZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ICU_Water_Watch.plot import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [-2.5, -2, -1.5, -1, 1, 1.5, 2, 2.5]\n",
    "\n",
    "rgbs = ['#F04E37', '#F99D1C', '#FFDE40', '#ffffff', '#96ceff', '#4553bf', '#09146b']\n",
    "\n",
    "ticks_marks = np.diff(np.array(thresholds)) / 2.\n",
    "\n",
    "ticks = [thresholds[i] + ticks_marks[i] for i in range(len(thresholds) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbar_kwargs={'shrink':0.5, 'pad':0.01, 'extend':'neither', 'drawedges':True, 'ticks':ticks, 'aspect':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colors.ListedColormap(rgbs, name='SPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarray = norm_spi_realtime['SPI'] * norm_spi_realtime['EEZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbar_ticklabels = ['- extremely dry','- severely dry','- moderately dry',' ', '- moderately wet','- severely wet','- extremely wet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day = datetime(last_day.year, last_day.month, last_day.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13, 8), subplot_kw={'projection':ccrs.PlateCarree(central_longitude=180)})\n",
    "\n",
    "im = dataarray.plot.contourf(ax=ax, levels=thresholds, cmap=cmap, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "\n",
    "# adds the colorbar axes as insets \n",
    "\n",
    "cbar_ax = ax.axes.inset_axes([0.80, 0.5225, 0.025, 0.38])\n",
    "\n",
    "# plots the colorbar in these axes \n",
    "\n",
    "cb = plt.colorbar(im, cax=cbar_ax, **cbar_kwargs)\n",
    "\n",
    "cb.ax.minorticks_off() \n",
    "\n",
    "cb.ax.tick_params(size=0)\n",
    "\n",
    "# plots the ticklabels \n",
    "\n",
    "cbar_ax.set_yticklabels(cbar_ticklabels)\n",
    "\n",
    "ax.coastlines(resolution='10m')\n",
    "\n",
    "EEZs.boundary.plot(ax=ax, transform=ccrs.PlateCarree(), color='0.4', linewidth=0.8)\n",
    "\n",
    "title = f\"GPM-IMERG, Standardized Precipitation Index (SPI)\"\n",
    "\n",
    "ax.set_title(\"\") # to get rid of the default title\n",
    "\n",
    "ax.text(0.99, 0.95, title, fontsize=13, fontdict={'color':'k'}, bbox=dict(facecolor='w', edgecolor='w'), horizontalalignment='right', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "ax.set_extent(domain, crs = ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(f'./SPI_ICU_prototype_{ndays}_days_to_{last_day:%Y%m%d}.png', dpi=200, bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
